# 1.线程池结构
线程池模块中有工作线程和事件请求处理线程，工作线程默认有4个，事件请求处理线程只有1个  
为每个工作线程都维持一个工作任务队列，事件请求处理线程会将任务分配到每个线程的工作任务队列上  
必须要注意工作线程的线程安全，要使用线程安全的函数！！！  

# 2.线程池工作流程
每当epoll监听到套接字上有新的可读或可写事件发生时就将该事件传递到事件请求处理线程上，为了提高效率，事件请求处理线程会维持两个事件队列，分别是事件请求缓冲队列和事件请求处理队列，只要有新的事件请求，就投入事件请求缓冲队列，事件处理分配器处理完当前任务先对事件请求缓冲队列加锁，然后读取事件请求缓冲队列，随后解锁，处理事件请求处理队列，这样可以避免频繁的加锁和解锁。事件处理分配线程将任务分配到各工作队列后，各工作线程会执行各自工作队列上的任务。   

# 3.实现中的思考
《linux高性能服务器编程》中第15章的示例程序还可以进一步改进以提升性能
1) 代码中epoll主循环中有如下代码，这里的业务处理函数read()和write()影响了epoll的效率，延误了服务器对于连接的响应速度，改为建立一个事件分配线程专门进行read()和write()函数的调用及任务的分配  
```c++
else if( events[i].events & EPOLLIN )  
{                                      
    if( users[sockfd].read() )         
    {                                  
        pool->append( users + sockfd );
    }                                  
    else                               
    {                                  
        users[sockfd].close_conn();    
    }                                  
}                                      
else if( events[i].events & EPOLLOUT ) 
{                                      
    if( !users[sockfd].write() )       
    {                                  
        users[sockfd].close_conn();    
    }                                  
} 
```

2）半同步半反应堆模式的缺点    
   1、主线程和工作线程共享请求队列，对请求队列的操作需求加锁，耗费CPU时间。    
   
   2、每一个工作线程在同一时间只能处理一个客户请求。客户数量多，工作线程少，请求队列任务堆积，响应满，如果添加试图通过增加线程则，由于线程切换导致的CPU时间消耗。   
   
   对于第一个缺点，改进方法是维持一个事件处理分配器，其中实现对事件请求的分析及任务的分配，其中维持两个队列，事件请求缓冲队列和事件请求处理队列，只要有新的事件请求，就投入事件请求缓冲队列，事件处理分配器处理完当前任务先对事件请求缓冲队列加锁，然后读取事件请求缓冲队列，随后解锁，处理事件请求处理队列，这样可以避免频繁的加锁和解锁。
   本程序中建立两个队列buff_work_queue和deal_work_queue  
   
3）为每个工作线程建立一个工作任务队列，同时建立一个事件请求处理线程，负责任务的分配
原程序只维持一个工作任务队列，通过线程间信号量的方式去通知各工作线程进行资源的竞争，会导致惊群效应，改为事件请求处理线程分配任务可以解决此问题。

**惊群效应:**   
引用一个比较好的讲解，作者：second60 原文：https://blog.csdn.net/second60/article/details/81252106 

当你往一群鸽子中间扔一块食物，虽然最终只有一个鸽子抢到食物，但所有鸽子都会被惊动来争夺，没有抢到食物的鸽子只好回去继续睡觉， 等待下一块食物到来。这样，每扔一块食物，都会惊动所有的鸽子，即为惊群。
简单地说：就是扔一块食物，所有鸽子来抢，但最终只一个鸽子抢到了食物。
语义分析：食物只有一块，最终只有一个鸽子抢到，但是惊动了所有鸽子，每个鸽子都跑过来，消耗了每个鸽子的能量。

在多进程/多线程等待同一资源时，也会出现惊群。即当某一资源可用时，多个进程/线程会惊醒，竞争资源。这就是操作系统中的惊群。

坏处：  
1.惊醒所有进程/线程，导致n-1个进程/线程做了无效的调度，上下文切换，cpu瞬时增高  
2.多个进程/线程争抢资源，所以涉及到同步问题，需对资源进行加锁保护，加解锁加大系统CPU开销  

在多线程设计中，经常会用到互斥和条件变量的问题。当一个线程解锁并通知其他线程的时候，就会出现惊群的现象。  
pthread_mutex_lock/pthread_mutex_unlock：线程互斥锁的加锁及解锁函数。  
pthread_cond_wait：线程池中的消费者线程等待线程条件变量被通知；  
pthread_cond_signal/pthread_cond_broadcast：生产者线程通知线程池中的某个或一些消费者线程池，接收处理任务；  
pthread_cond_signal调用后，系统会唤醒在相同条件变量上等待的一个或多个线程（可参看手册）。如果通知了多个线程，则发生了惊群。

正常的用法：  
所有线程共用一个锁，共用一个条件变量  
当pthread_cond_signal通知时，就可能会出现惊群   

解决惊群的方法：  
所有线程共用一个锁，每个线程有自已的条件变量  
pthread_cond_signal通知时，定向通知某个线程的条件变量，不会出现惊群  

# 4.编写中的思考
1)pthread_create中要求第三个参数为静态成员函数，需要注意
```c++
	static void *worker(void *); //工作线程，注意为静态成员函数
	static void *dealer(void *); //事件请求处理线程，注意为静态成员函数
	void worker_run(void *); //工作线程实体
	void dealer_run(); //事件请求处理线程实体
```
2)事件请求处理线程代码如下，需要注意到是先检查事件请求缓冲队列是否有数据，然后拷贝到事件请求处理队列上进行处理，减少频繁的开关锁  
任务的分配采用轮询调度算法(Round-Robin Scheduling)，比较简单
```c++
void Threadpool::dealer_run()
{
	while(!flag_stop)
	{
		printf("事件请求处理线程等待\n");
		buff_queue_lock.lock();
		while(buff_request_number == 0)
			Pthread_cond_wait(&deal_cond,&buff_queue_lock.m_mutex);

                deal_queue_lock.lock();
		printf("事件请求处理线程唤醒，当前共有%d个事件请求\n",buff_request_number);
		while(!buff_work_queue.empty()) //将buff_work_queue中的请求转到deal_work_queue
		{
			deal_work_queue.push(buff_work_queue.front());
			buff_work_queue.pop();
			--buff_request_number; //记得减去,否则cond的触发会有问题，注意是批量读取
		}
		buff_queue_lock.unlock();

		//处理deal_work_queue中的事件请求，随后将其分给各工作线程的工作队列，并通知各工作线程
		for(static int i=0;!deal_work_queue.empty();++i) // static int i  下次进入时仍然记得之前分配的位置
		{
			Httpcon* request = deal_work_queue.front();
			deal_work_queue.pop();

			if(!request)
				continue;
			if( deal_request(request) )//处理请求
			{
				//此处只是简单的循环分发任务 轮询调度算法(Round-Robin Scheduling)
				i%=thread_number;
				printf("当前任务被分配给线程%d\n",i);
				single_work_mutex[i].lock();
				single_work_queue[i].push(request);
			   ++single_request_number[i];
			   Pthread_cond_signal(&single_cond[i]); //发出信号
				single_work_mutex[i].unlock();
			}
			else
			{
				--i;
			}
		}
		deal_queue_lock.unlock();
	}
	printf("线程终止运行\n");
}
```
3）工作线程代码如下，需要注意到每次处理任务时要解锁工作队列，时间请求处理线程此时可以将新的任务添加到工作队列上
```c++
void Threadpool::worker_run(void *arg)
{
	int cur_thread_id;
	int complete_work=0;
	send_data *temp=(send_data *)arg;  //对传入的数据分解
	cur_thread_id=temp->thread_id;
	delete temp; //回收动态分配的内存

	//线程处理自己工作队列上的任务
	 while ( ! flag_stop )
	 {
		 printf("工作线程%d等待\n",cur_thread_id);
		 single_work_mutex[cur_thread_id].lock();
		 while(single_request_number[cur_thread_id]== 0)
				Pthread_cond_wait(&single_cond[cur_thread_id],&single_work_mutex[cur_thread_id].m_mutex);
		 printf("工作线程%d唤醒\n",cur_thread_id);

		 if(single_work_queue[cur_thread_id].empty())
		 {
			 single_work_mutex[cur_thread_id].unlock();
			 printf("single_work_queue miss request\n"); //正常不可能丢失任务
			 continue;
		 }

		 while(!single_work_queue[cur_thread_id].empty()) //循环处理工作队列上的任务，注意循环处理的时候事件请求处理线程可能还在往工作队列上添加任务
		 {
			 printf("工作线程%d的工作队列上有%d个任务在等待被处理\n",cur_thread_id,(int)single_work_queue[cur_thread_id].size());
			 Httpcon *request;
			 request=single_work_queue[cur_thread_id].front();
			 single_work_queue[cur_thread_id].pop();
			 --single_request_number[cur_thread_id];  //记得计数器减1
			 single_work_mutex[cur_thread_id].unlock(); //一旦找到当前的任务就解锁，方便事件请求处理线程分配新的工作

			 if(!request) //判断是否是无效任务
			 {
				 printf("无效任务\n");
				 single_work_mutex[cur_thread_id].lock(); //注意上锁
				 continue;
			 }

			 request->process();  //预计是一个很耗费时间的工作
			 ++complete_work; //计数器加1
			 printf("工作线程%d已经处理了%d个任务\n",cur_thread_id,complete_work);

			 single_work_mutex[cur_thread_id].lock(); //注意上锁
	    }
		single_work_mutex[cur_thread_id].unlock(); //注意解锁
	 }
	 printf("线程终止运行\n");
}

```
4）对于进程池终止标志位的设置，多线程下编译器有时会对变量乱优化，将内存中flag_stop的值放到寄存器中，当flag_stop在内存中被修改时，其他线程还在读取寄存器中的值，会出现错误，此错误之前碰到过，需要注意，c++11的新类型atomic是目前看来最好的，volatile不能保证线程间可知性，atomic可以做到这一点

```c++
bool flag_stop; //进程池终止标志位

volatile bool flag_stop; //进程池终止标志位,使用volatile，一般

atomic<bool>  flag_stop; //进程池终止标志位,使用atomic，最好
```

# 5.程序源码
```c++
#ifndef THREADPOOL_H_
#define THREADPOOL_H_

extern "C" {
  #include <stdio.h>
  #include <stdlib.h>
  #include "unpthread.h"
}

#include "Httpcon.h"
#include "locker.h"
#include <iostream>
#include <queue>

class Threadpool {
public:
	Threadpool(int default_thread_number=4 ); //默认4个线程
	virtual ~Threadpool();
	bool append(Httpcon*);

private:
	static void *worker(void *); //工作线程，注意为静态成员函数
	static void *dealer(void *); //事件请求处理线程，注意为静态成员函数
	void worker_run(void *); //工作线程实体
	void dealer_run(); //事件请求处理线程实体
	int deal_request(Httpcon*); //事件请求处理函数

	int thread_number; //线程池线程个数
	pthread_t *threads; //记录线程号
	std::queue<Httpcon*> *single_work_queue; //为每个工作线程建立一个工作任务队列
	locker	*single_work_mutex; //为每个工作任务队列建立一个互斥锁
	int *single_request_number; //为每个工作线程建立一个任务计数器
	pthread_cond_t *single_cond; //为每个工作线程建立一个条件变量

	volatile bool flag_stop; //进程池终止标志位,使用volatile

	std::queue<Httpcon*> buff_work_queue; //总的事件请求缓冲队列
	int buff_request_number; //事件请求的个数
	pthread_cond_t deal_cond; //事件请求条件变量
	std::queue<Httpcon*> deal_work_queue; //总的事件请求处理队列
	locker buff_queue_lock; //事件请求缓冲队列互斥锁
	locker deal_queue_lock; //事件请求处理队列互斥锁
	pthread_t deal_thread; //事件请求处理线程号

	typedef struct
	{
		 Threadpool *pool; //因为worker()、dealer()函数为静态成员函数，所以要传类指针进去
	    int thread_id;
	}send_data;  //用于线程池创建时将线程信息传进去
};

#endif /* THREADPOOL_H_ */

#include "Threadpool.h"

Threadpool::Threadpool(int default_thread_number):thread_number(default_thread_number),threads(NULL),
single_work_queue(NULL),single_work_mutex(NULL),single_request_number(NULL),single_cond(NULL),flag_stop(false),buff_request_number(0)
{
	if(thread_number<0)
	{
		err_quit("thread_number error");
	}

	threads=new pthread_t[thread_number];
	if(!threads)
	{
		err_quit("threads error");
	}

	single_work_queue=new std::queue<Httpcon*>[thread_number];
	if(!single_work_queue)
	{
		delete []threads;
		err_quit("single_work_queue error");
	}

	single_work_mutex=new locker[thread_number];
	if(!single_work_mutex)
	{
		delete []threads;
		delete []single_work_queue;
		err_quit("single_work_mutex error");
	}

	single_request_number=new int[thread_number];
	if(!single_request_number)
	{
		delete []threads;
		delete []single_work_queue;
		delete []single_work_mutex;
		err_quit("single_work_mutex error");
	}

	for(int i=0;i<thread_number;++i) //记得初始化计数器为0
		single_request_number[i]=0;

	single_cond=new pthread_cond_t[thread_number];
	if(!single_cond)
	{
		delete []threads;
		delete []single_work_queue;
		delete []single_work_mutex;
		delete []single_request_number;
		err_quit("single_queue_stat error");
	}

	for(int i=0;i<thread_number;++i) //初始化条件变量
	{
		if( pthread_cond_init(single_cond+i,NULL) >0)
		{
			delete []threads;
			delete []single_work_queue;
			delete []single_work_mutex;
			delete []single_request_number;
			delete []single_cond;
			err_quit("pthread_cond_init error");
		}
	}

	for(int i=0;i<thread_number;++i) //建立各工作线程
	{
		printf("create %d thread\n",i);
		send_data *temp=new send_data; //send_data用于传递数据
		temp->pool=this;
		temp->thread_id=i;
		if( pthread_create(threads+i,NULL,worker,(void*)temp) >0 ) //建立各工作线程，temp中存储要传递的数据
		{
			delete []threads;
			delete []single_work_queue;
			delete []single_work_mutex;
			delete []single_request_number;
			delete []single_cond;
			err_quit("phread_create error");
		}
		if( pthread_detach(threads[i]) >0 ) //分离各工作线程
		{
			delete []threads;
			delete []single_work_queue;
			delete []single_work_mutex;
			delete []single_request_number;
			delete []single_cond;
			err_quit("phread_detach error");
		}
	}

	if( pthread_create(&deal_thread,NULL,dealer,this) >0 ) //建立事件请求处理线程
	{
		delete []threads;
		delete []single_work_queue;
		delete []single_work_mutex;
		delete []single_request_number;
		delete []single_cond;
		err_quit("deal pthread_create error");
	}

	if( pthread_detach(deal_thread) >0 )  //分离事件请求处理线程
	{
		delete []threads;
		delete []single_work_queue;
		delete []single_work_mutex;
		delete []single_request_number;
		delete []single_cond;
		err_quit("deal pthread_create error");
	}

	if( pthread_cond_init(&deal_cond,NULL) >0) //初始化事件请求处理线程的条件变量
	{
		delete []threads;
		delete []single_work_queue;
		delete []single_work_mutex;
		delete []single_request_number;
		delete []single_cond;
		err_quit("pthread_cond_init error");
	}
}

Threadpool::~Threadpool()
{
	delete []threads;
	delete []single_work_queue;
	delete []single_work_mutex;
	delete []single_request_number;
	delete []single_cond;
	flag_stop=true;
}


bool Threadpool::append( Httpcon* request ) //向事件请求缓冲队列中添加一个事件请求
{
	//注意要对事件请求缓冲队列上锁
	if(request)
	{
		 buff_queue_lock.lock();
	    buff_work_queue.push( request );
	    ++buff_request_number;
	    Pthread_cond_signal(&deal_cond); //发出信号
	    buff_queue_lock.unlock();
	    return true;
	}
	else
	{
		return false;
	}
}

void* Threadpool::worker( void* arg )
{
	 send_data *temp=(send_data *)arg;  //对传入的数据分解
    Threadpool* pool =temp->pool;
    pool->worker_run(arg);
    return pool;
}

void* Threadpool::dealer( void* arg )
{
    Threadpool* pool = ( Threadpool* )arg;
    pool->dealer_run();
    return pool;
}

void Threadpool::dealer_run()
{
	while(!flag_stop)
	{
		printf("事件请求处理线程等待\n");
		buff_queue_lock.lock();
		while(buff_request_number == 0)
			Pthread_cond_wait(&deal_cond,&buff_queue_lock.m_mutex);


                deal_queue_lock.lock();
		printf("事件请求处理线程唤醒，当前共有%d个事件请求\n",buff_request_number);
		while(!buff_work_queue.empty()) //将buff_work_queue中的请求转到deal_work_queue
		{
			deal_work_queue.push(buff_work_queue.front());
			buff_work_queue.pop();
			--buff_request_number; //记得减去,否则cond的触发会有问题，注意是批量读取
		}
		buff_queue_lock.unlock();

		//处理deal_work_queue中的事件请求，随后将其分给各工作线程的工作队列，并通知各工作线程
		for(static int i=0;!deal_work_queue.empty();++i) // static int i  下次进入时仍然记得之前分配的位置
		{
			Httpcon* request = deal_work_queue.front();
			deal_work_queue.pop();

			if(!request)
				continue;
			if( deal_request(request) )//处理请求
			{
				//此处只是简单的循环分发任务  轮询调度算法(Round-Robin Scheduling)
				i%=thread_number;
				printf("当前任务被分配给线程%d\n",i);
				single_work_mutex[i].lock();
				single_work_queue[i].push(request);
			   ++single_request_number[i];
			   Pthread_cond_signal(&single_cond[i]); //发出信号
				single_work_mutex[i].unlock();
			}
			else
			{
				--i;
			}
		}
		deal_queue_lock.unlock();
	}
	printf("线程终止运行\n");
}

int Threadpool::deal_request(Httpcon*) //处理请求
{
	return 1;
}

void Threadpool::worker_run(void *arg)
{
	int cur_thread_id;
	int complete_work=0;
	send_data *temp=(send_data *)arg;  //对传入的数据分解
	cur_thread_id=temp->thread_id;
	delete temp; //回收动态分配的内存

	//线程处理自己工作队列上的任务
	 while ( ! flag_stop )
	 {
		 printf("工作线程%d等待\n",cur_thread_id);
		 single_work_mutex[cur_thread_id].lock();
		 while(single_request_number[cur_thread_id]== 0)
				Pthread_cond_wait(&single_cond[cur_thread_id],&single_work_mutex[cur_thread_id].m_mutex);
		 printf("工作线程%d唤醒\n",cur_thread_id);

		 if(single_work_queue[cur_thread_id].empty())
		 {
			 single_work_mutex[cur_thread_id].unlock();
			 printf("single_work_queue miss request\n"); //正常不可能丢失任务
			 continue;
		 }

		 while(!single_work_queue[cur_thread_id].empty()) //循环处理工作队列上的任务，注意循环处理的时候事件请求处理线程可能还在往工作队列上添加任务
		 {
			 printf("工作线程%d的工作队列上有%d个任务在等待被处理\n",cur_thread_id,(int)single_work_queue[cur_thread_id].size());
			 Httpcon *request;
			 request=single_work_queue[cur_thread_id].front();
			 single_work_queue[cur_thread_id].pop();
			 --single_request_number[cur_thread_id];  //记得计数器减1
			 single_work_mutex[cur_thread_id].unlock(); //一旦找到当前的任务就解锁，方便事件请求处理线程分配新的工作

			 if(!request) //判断是否是无效任务
			 {
				 printf("无效任务\n");
				 single_work_mutex[cur_thread_id].lock(); //注意上锁
				 continue;
			 }

			 request->process();  //预计是一个很耗费时间的工作
			 ++complete_work; //计数器加1
			 printf("工作线程%d已经处理了%d个任务\n",cur_thread_id,complete_work);

			 single_work_mutex[cur_thread_id].lock(); //注意上锁
	    }
		single_work_mutex[cur_thread_id].unlock(); //注意解锁
	 }
	 printf("线程终止运行\n");
}

```
# 6.程序源码(加上日志后)
```c++
#ifndef THREADPOOL_H_
#define THREADPOOL_H_

extern "C" {
  #include <stdio.h>
  #include <stdlib.h>
  #include "unpthread.h"
}

#include "Serverlog.h"
#include "Httpcon.h"
#include "locker.h"
#include <iostream>
#include <queue>

class Threadpool {
public:
	Threadpool(Serverlog *m_log,int default_thread_number=4); //默认4个线程
	virtual ~Threadpool();
	bool append(Httpcon*);

private:
	static void *worker(void *); //工作线程，注意为静态成员函数
	static void *dealer(void *); //事件请求处理线程，注意为静态成员函数
	void worker_run(void *); //工作线程实体
	void dealer_run(); //事件请求处理线程实体
	int deal_request(Httpcon*); //事件请求处理函数

	int thread_number; //线程池线程个数
	Serverlog *log; //日志
	pthread_t *threads; //记录线程号
	std::queue<Httpcon*> *single_work_queue; //为每个工作线程建立一个工作任务队列
	locker	*single_work_mutex; //为每个工作任务队列建立一个互斥锁
	int *single_request_number; //为每个工作线程建立一个任务计数器
	pthread_cond_t *single_cond; //为每个工作线程建立一个条件变量

	volatile bool flag_stop; //进程池终止标志位,使用volatile

	std::queue<Httpcon*> buff_work_queue; //总的事件请求缓冲队列
	int buff_request_number; //事件请求的个数
	pthread_cond_t deal_cond; //事件请求条件变量
	std::queue<Httpcon*> deal_work_queue; //总的事件请求处理队列
	locker buff_queue_lock; //事件请求缓冲队列互斥锁
	locker deal_queue_lock; //事件请求处理队列互斥锁
	pthread_t deal_thread; //事件请求处理线程号

	typedef struct
	{
		 Threadpool *pool; //因为worker()、dealer()函数为静态成员函数，所以要传类指针进去
	    int thread_id;
	}send_data;  //用于线程池创建时将线程信息传进去
};

#endif /* THREADPOOL_H_ */

#include "Threadpool.h"

Threadpool::Threadpool(Serverlog *m_log,int default_thread_number):thread_number(default_thread_number),log(m_log),threads(NULL),
single_work_queue(NULL),single_work_mutex(NULL),single_request_number(NULL),single_cond(NULL),flag_stop(false),buff_request_number(0)
{
	if(thread_number<0)
	{
		log->append_log((std::string)"thread_number error");
		err_quit("thread_number error");
	}

	threads=new pthread_t[thread_number];
	if(!threads)
	{
		log->append_log((std::string)"threads error");
		err_quit("threads error");
	}

	single_work_queue=new std::queue<Httpcon*>[thread_number];
	if(!single_work_queue)
	{
		delete []threads;
		log->append_log((std::string)"single_work_queue error");
		err_quit("single_work_queue error");
	}

	single_work_mutex=new locker[thread_number];
	if(!single_work_mutex)
	{
		delete []threads;
		delete []single_work_queue;
		log->append_log((std::string)"single_work_mutex error");
		err_quit("single_work_mutex error");
	}

	single_request_number=new int[thread_number];
	if(!single_request_number)
	{
		delete []threads;
		delete []single_work_queue;
		delete []single_work_mutex;
		log->append_log((std::string)"single_work_mutex error");
		err_quit("single_work_mutex error");
	}

	for(int i=0;i<thread_number;++i) //记得初始化计数器为0
		single_request_number[i]=0;

	single_cond=new pthread_cond_t[thread_number];
	if(!single_cond)
	{
		delete []threads;
		delete []single_work_queue;
		delete []single_work_mutex;
		delete []single_request_number;
		log->append_log((std::string)"single_queue_stat error");
		err_quit("single_queue_stat error");
	}

	for(int i=0;i<thread_number;++i) //初始化条件变量
	{
		if( pthread_cond_init(single_cond+i,NULL) >0)
		{
			delete []threads;
			delete []single_work_queue;
			delete []single_work_mutex;
			delete []single_request_number;
			delete []single_cond;
			log->append_log((std::string)"pthread_cond_init error");
			err_quit("pthread_cond_init error");
		}
	}

	for(int i=0;i<thread_number;++i) //建立各工作线程
	{
		printf("create %d thread\n",i);
		log->append_log((std::string)"create "+std::to_string(i)+(std::string)" thread");
		send_data *temp=new send_data; //send_data用于传递数据
		temp->pool=this;
		temp->thread_id=i;
		if( pthread_create(threads+i,NULL,worker,(void*)temp) >0 ) //建立各工作线程，temp中存储要传递的数据
		{
			delete []threads;
			delete []single_work_queue;
			delete []single_work_mutex;
			delete []single_request_number;
			delete []single_cond;
			log->append_log((std::string)"phread_create error");
			err_quit("phread_create error");
		}
		if( pthread_detach(threads[i]) >0 ) //分离各工作线程
		{
			delete []threads;
			delete []single_work_queue;
			delete []single_work_mutex;
			delete []single_request_number;
			delete []single_cond;
			log->append_log((std::string)"phread_detach error");
			err_quit("phread_detach error");
		}
	}

	if( pthread_create(&deal_thread,NULL,dealer,this) >0 ) //建立事件请求处理线程
	{
		delete []threads;
		delete []single_work_queue;
		delete []single_work_mutex;
		delete []single_request_number;
		delete []single_cond;
		log->append_log((std::string)"deal pthread_create error");
		err_quit("deal pthread_create error");
	}

	if( pthread_detach(deal_thread) >0 )  //分离事件请求处理线程
	{
		delete []threads;
		delete []single_work_queue;
		delete []single_work_mutex;
		delete []single_request_number;
		delete []single_cond;
		log->append_log((std::string)"deal pthread_create error");
		err_quit("deal pthread_create error");
	}

	if( pthread_cond_init(&deal_cond,NULL) >0) //初始化事件请求处理线程的条件变量
	{
		delete []threads;
		delete []single_work_queue;
		delete []single_work_mutex;
		delete []single_request_number;
		delete []single_cond;
		log->append_log((std::string)"pthread_cond_init error");
		err_quit("pthread_cond_init error");
	}
}

Threadpool::~Threadpool()
{
	log->append_log((std::string)"threadpool stop");
	delete []threads;
	delete []single_work_queue;
	delete []single_work_mutex;
	delete []single_request_number;
	delete []single_cond;
	flag_stop=true;
}


bool Threadpool::append( Httpcon* request ) //向事件请求缓冲队列中添加一个事件请求
{
	//注意要对事件请求缓冲队列上锁
	if(request)
	{
		 buff_queue_lock.lock();
	    buff_work_queue.push( request );
	    ++buff_request_number;
	    Pthread_cond_signal(&deal_cond); //发出信号
	    buff_queue_lock.unlock();
	    return true;
	}
	else
	{
		return false;
	}
}

void* Threadpool::worker( void* arg )
{
	 send_data *temp=(send_data *)arg;  //对传入的数据分解
    Threadpool* pool =temp->pool;
    pool->worker_run(arg);
    return pool;
}

void* Threadpool::dealer( void* arg )
{
    Threadpool* pool = ( Threadpool* )arg;
    pool->dealer_run();
    return pool;
}

void Threadpool::dealer_run()
{
	while(!flag_stop)
	{
		printf("事件请求处理线程等待\n");
		log->append_log((std::string)"dealer_run thread wait");
		buff_queue_lock.lock();
		while(buff_request_number == 0)
			Pthread_cond_wait(&deal_cond,&buff_queue_lock.m_mutex);

		printf("事件请求处理线程唤醒，当前共有%d个事件请求\n",buff_request_number);
		log->append_log((std::string)"dealer_run thread awake,now has "+std::to_string(buff_request_number)+(std::string)"request");
		while(!buff_work_queue.empty()) //将buff_work_queue中的请求转到deal_work_queue
		{
			deal_work_queue.push(buff_work_queue.front());
			buff_work_queue.pop();
			--buff_request_number; //记得减去,否则cond的触发会有问题，注意是批量读取
		}
		buff_queue_lock.unlock();

		deal_queue_lock.lock();
		//处理deal_work_queue中的事件请求，随后将其分给各工作线程的工作队列，并通知各工作线程
		for(static int i=0;!deal_work_queue.empty();++i) // static int i  下次进入时仍然记得之前分配的位置
		{
			Httpcon* request = deal_work_queue.front();
			deal_work_queue.pop();

			if(!request)
				continue;
			if( deal_request(request) )//处理请求
			{
				//此处只是简单的循环分发任务  轮询调度算法(Round-Robin Scheduling)
				i%=thread_number;
				printf("当前任务被分配给线程%d\n",i);
				log->append_log((std::string)"current request is sent to "+std::to_string(i)+(std::string)" thread");
				single_work_mutex[i].lock();
				single_work_queue[i].push(request);
			   ++single_request_number[i];
			   Pthread_cond_signal(&single_cond[i]); //发出信号
				single_work_mutex[i].unlock();
			}
			else
			{
				--i;
			}
		}
		deal_queue_lock.unlock();
	}
	printf("线程终止运行\n");
	log->append_log((std::string)"thread stop");
}

int Threadpool::deal_request(Httpcon*) //处理请求
{
	return 1;
}

void Threadpool::worker_run(void *arg)
{
	int cur_thread_id;
	int complete_work=0;
	send_data *temp=(send_data *)arg;  //对传入的数据分解
	cur_thread_id=temp->thread_id;
	delete temp; //回收动态分配的内存

	//线程处理自己工作队列上的任务
	 while ( ! flag_stop )
	 {
		 printf("工作线程%d等待\n",cur_thread_id);
		 log->append_log((std::string)"worker thread "+std::to_string(cur_thread_id)+(std::string)" wait");

		 single_work_mutex[cur_thread_id].lock();
		 while(single_request_number[cur_thread_id]== 0)
				Pthread_cond_wait(&single_cond[cur_thread_id],&single_work_mutex[cur_thread_id].m_mutex);

		 printf("工作线程%d唤醒\n",cur_thread_id);
		 log->append_log((std::string)"worker thread "+std::to_string(cur_thread_id)+(std::string)" awake");

		 if(single_work_queue[cur_thread_id].empty())
		 {
			 single_work_mutex[cur_thread_id].unlock();
			 printf("single_work_queue miss request\n"); //正常不可能丢失任务
			 log->append_log((std::string)"single_work_queue miss request");
			 continue;
		 }

		 while(!single_work_queue[cur_thread_id].empty()) //循环处理工作队列上的任务，注意循环处理的时候事件请求处理线程可能还在往工作队列上添加任务
		 {
			 printf("工作线程%d的工作队列上有%d个任务在等待被处理\n",cur_thread_id,(int)single_work_queue[cur_thread_id].size());
			 log->append_log((std::string)"worker thread "+std::to_string(cur_thread_id)+(std::string)" need to deal "+std::to_string((int)single_work_queue[cur_thread_id].size())+(std::string)" request");
			 Httpcon *request;
			 request=single_work_queue[cur_thread_id].front();
			 single_work_queue[cur_thread_id].pop();
			 --single_request_number[cur_thread_id];  //记得计数器减1
			 single_work_mutex[cur_thread_id].unlock(); //一旦找到当前的任务就解锁，方便事件请求处理线程分配新的工作

			 if(!request) //判断是否是无效任务
			 {
				 printf("无效任务\n");
				 log->append_log((std::string)"error request");
				 single_work_mutex[cur_thread_id].lock(); //注意上锁
				 continue;
			 }

			 request->process();  //预计是一个很耗费时间的工作
			 ++complete_work; //计数器加1
			 printf("工作线程%d已经处理了%d个任务\n",cur_thread_id,complete_work);
			 log->append_log((std::string)"worker thread "+std::to_string(cur_thread_id)+(std::string)" alrealy deal "+std::to_string(complete_work)+(std::string)" request");

			 single_work_mutex[cur_thread_id].lock(); //注意上锁
	    }
		single_work_mutex[cur_thread_id].unlock(); //注意解锁
	 }
	 printf("线程终止运行\n");
	 log->append_log((std::string)"thread end work");
}
```
